{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up tracking server\n",
    "TRACKING_SERVER_HOST = \"34.68.82.207\" #external IP reserved in GCP\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://34.68.82.207:5000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/processed/202304-usage.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/24 13:52:46 INFO mlflow.tracking.fluent: Experiment with name 'experiment-4' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='gs://mlops-divvy-experiment-tracking/mlruns/4', creation_time=1721847166117, experiment_id='4', last_update_time=1721847166117, lifecycle_stage='active', name='experiment-4', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"experiment-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m transformed_X_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([num_scaled_train, ohe_cols_train], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m transformed_X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([num_scaled_test, ohe_cols_test], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mparams\u001b[49m)\u001b[38;5;241m.\u001b[39mfit(transformed_X_train, y_train)\n\u001b[1;32m     37\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(transformed_X_test)\n\u001b[1;32m     38\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_squared_error(y_test, y_pred))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    #load prepared data\n",
    "    df = pd.read_parquet(data_file)\n",
    "    mlflow.log_param(\"data_file\", data_file)\n",
    "\n",
    "    features = df[['station_name', 'hour', 'day_of_week']]\n",
    "    target = df['net_usage']\n",
    "\n",
    "    num_features= ['hour']\n",
    "    cat_features = ['station_name', 'day_of_week']\n",
    "\n",
    "    split_params = {\"test_size\": 0.2, \"random_state\": 42}\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, **split_params)\n",
    "\n",
    "    Standard_Scaler = StandardScaler()\n",
    "    num_scaled_train = pd.DataFrame(Standard_Scaler.fit_transform(X_train[num_features]), columns=['hour_scaled'])\n",
    "    num_scaled_test = pd.DataFrame(Standard_Scaler.transform(X_test[num_features]), columns=['hour_scaled'])\n",
    "\n",
    "    num_scaled_train.index = X_train.index\n",
    "    num_scaled_test.index = X_test.index\n",
    "\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    ohe_cols_train = ohe.fit_transform(X_train[cat_features])\n",
    "    ohe_cols_test = ohe.transform(X_test[cat_features])\n",
    "\n",
    "    ohe_cols_train = pd.DataFrame(ohe.fit_transform(X_train[cat_features]).toarray(), columns = ohe.get_feature_names_out(cat_features))\n",
    "    ohe_cols_test = pd.DataFrame(ohe.transform(X_test[cat_features]).toarray(), columns = ohe.get_feature_names_out(cat_features))\n",
    "\n",
    "    ohe_cols_train.index = X_train.index\n",
    "    ohe_cols_test.index = X_test.index\n",
    "\n",
    "    transformed_X_train = pd.concat([num_scaled_train, ohe_cols_train], axis=1)\n",
    "    transformed_X_test = pd.concat([num_scaled_test, ohe_cols_test], axis=1)\n",
    "\n",
    "    params = {\"n_estimators\": 10, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "    rf = RandomForestRegressor(**params).fit(transformed_X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(transformed_X_test)\n",
    "    mlflow.log_metric(\"mse\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(rf, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
