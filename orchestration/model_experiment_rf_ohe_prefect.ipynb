{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from prefect import flow, task\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "\n",
    "import evidently\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils imports\n",
    "from utils.get_data.download_data import download_file\n",
    "from utils.data_preprocessing.data_preparation import load_dataframe, remove_missing_data, create_hour_weekday, transform_df_target, extract_station_info\n",
    "from utils.data_processing.feature_encode_scale import encode_categorical, scale_numerical\n",
    "from utils.data_processing.splitter import split_data\n",
    "from utils.save_data.save_to_gcs import save_multiple_dataframes_to_gcs_as_pkl, save_dataframe_to_gcs_as_parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download raw data, preprocess and create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_multiple_pkl_to_gcs(encoder_scaler, bucket_name, folder_path, file_name):\n",
    "    with io.BytesIO() as buffer:\n",
    "        pickle.dump(encoder_scaler, buffer)\n",
    "        buffer.seek(0)\n",
    "\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(f\"{folder_path}/{file_name}.pkl\")\n",
    "        blob.upload_from_file(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up mlflow experiment on prefect (https://medium.com/@rehabreda/mlflow-hyperopt-prefect-evidently-and-grafana-the-ultimate-guide-to-building-tracking-2d3591b6c1bd)\n",
    " \n",
    "@task\n",
    "def mlflow_environment(experiment_name):\n",
    "    TRACKING_SERVER_HOST = \"34.171.118.161\" #external IP reserved in GCP - updated Aug 8 2024\n",
    "    mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\") \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")\n",
    "\n",
    "    return experiment.experiment_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data and prepare data\n",
    "# @task\n",
    "# def download_data(year, month):\n",
    "    \n",
    "#     result = download_file(year, month)\n",
    "#     print(f'Downloaded file is available at {result[\"path\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def download_file(year, month):\n",
    "    month = str(month).zfill(2)\n",
    "    file= f'{year}{month}' #change to env variables year and month and path\n",
    "    path= './data/raw'\n",
    "    url=f'https://divvy-tripdata.s3.amazonaws.com/{file}-divvy-tripdata.zip'\n",
    "\n",
    "    resp=requests.get(url, stream=True)\n",
    "    zip_save_path = f'{path}/{file}.zip'\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    with open(zip_save_path,\"wb\") as handle:\n",
    "        for data in tqdm(resp.iter_content(chunk_size=1024),\n",
    "                        desc=f'{file}',\n",
    "                        postfix=f\"save to {zip_save_path}\",\n",
    "                        total=int(resp.headers[\"Content-Length\"])):\n",
    "            handle.write(data)\n",
    "\n",
    "    with zipfile.ZipFile(zip_save_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "    \n",
    "    os.remove(zip_save_path)\n",
    "\n",
    "    return {\n",
    "      \"path\": f'{path}/{year}{month}-divvy-tripdata.csv',\n",
    "      \"year\": year,\n",
    "      \"month\": month\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def prepare_dataset(year, month):\n",
    "    month = str(month).zfill(2)\n",
    "    path_input ='./data/raw'   \n",
    "    path_output ='./data/processed'\n",
    "    filename_input = f'{path_input}/{year}{month}-divvy-tripdata.csv'\n",
    "    filename_output = f'{path_output}/{year}{month}-usage.parquet'\n",
    "\n",
    "    df = load_dataframe(filename_input) \n",
    "    df = remove_missing_data(df)\n",
    "    df = create_hour_weekday(df)\n",
    "\n",
    "    usage_df = transform_df_target(df)\n",
    "\n",
    "    usage_df_final = extract_station_info(usage_df.copy())\n",
    "\n",
    "    usage_df_final.to_parquet(filename_output)\n",
    "\n",
    "    return path_output, filename_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, data processing and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def preprocess_data(data_file, split_params):\n",
    "    df = pd.read_parquet(data_file)\n",
    "    ohe, encoded_df = encode_categorical(df)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(encoded_df, split_params)\n",
    "\n",
    "    scaler, transformed_X_train, transformed_X_test, y_train, y_test = scale_numerical(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    return ohe, scaler, transformed_X_train, transformed_X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def save_dataframes_gcs(transformed_X_train, y_train, transformed_X_test, y_test, train_test_filename, test_filename):\n",
    "    bucket_name = 'mlops-divvy-experiment-tracking'\n",
    "    folder_path ='data/deployment'\n",
    "\n",
    "    dataframes =[transformed_X_train, y_train, transformed_X_test, y_test]\n",
    "\n",
    "    save_multiple_dataframes_to_gcs_as_pkl(dataframes, bucket_name, folder_path, train_test_filename)\n",
    "\n",
    "    transformed_test = pd.concat([transformed_X_test, y_test], axis =1)\n",
    "    save_dataframe_to_gcs_as_parquet(transformed_test, bucket_name, folder_path, test_filename)\n",
    "\n",
    "    print(f'transformed training and test sets saved in pkl, transformed set saved as parquet to deployment folder ')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def save_encoder_scaler(ohe, scaler,file_name):\n",
    "    encoder_scaler = [ohe, scaler]\n",
    "    bucket_name = 'mlops-divvy-experiment-tracking'\n",
    "    folder_path ='models/deployment'\n",
    "\n",
    "    save_multiple_pkl_to_gcs(encoder_scaler, bucket_name, folder_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def save_experiment_data(transformed_X_train,y_train, transformed_X_test, y_test, train_test_path, test_path):\n",
    "    with open(train_test_path, 'wb') as f: \n",
    "            pickle.dump((transformed_X_train, y_train, transformed_X_test, y_test), f)\n",
    "    transformed_test = pd.concat([transformed_X_test, y_test], axis =1)\n",
    "    transformed_test.to_parquet(test_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading daat function and task\n",
    "@task\n",
    "def load_prepared_data(data_file): \n",
    "    df = pd.read_parquet(data_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical data\n",
    "@task\n",
    "def encode_categorical(df):\n",
    "    cat_features = ['station_name', 'day_of_week']\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    ohe_cols = pd.DataFrame(ohe.fit_transform(df[cat_features]).toarray(), columns = ohe.get_feature_names_out(cat_features))\n",
    "    ohe_cols.index = df.index\n",
    "\n",
    "    encoded_df = pd.concat([df, ohe_cols], axis=1)\n",
    "    encoded_df = encoded_df.drop(cat_features, axis =1)\n",
    "\n",
    "    return ohe, encoded_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "@task\n",
    "def split_data(df, params):\n",
    "    features = df.drop(['net_usage'], axis =1)\n",
    "    target = df['net_usage']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, **params)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def scale_numerical(X_train, X_test, y_train, y_test):\n",
    "    num_features= ['hour']\n",
    "    Standard_Scaler = StandardScaler()\n",
    "    num_scaled_train = pd.DataFrame(Standard_Scaler.fit_transform(X_train[num_features]), columns=['hour_scaled'])\n",
    "    num_scaled_test = pd.DataFrame(Standard_Scaler.transform(X_test[num_features]), columns=['hour_scaled'])\n",
    "\n",
    "    num_scaled_train.index = X_train.index\n",
    "    num_scaled_test.index = X_test.index\n",
    "\n",
    "    scaled_X_train = pd.concat([X_train, num_scaled_train], axis=1)\n",
    "    scaled_X_test = pd.concat([X_test, num_scaled_test], axis=1)\n",
    "\n",
    "    scaled_X_train = scaled_X_train.drop(num_features, axis=1)\n",
    "    scaled_X_test = scaled_X_test.drop(num_features, axis=1)\n",
    "\n",
    "    return Standard_Scaler, scaled_X_train, scaled_X_test, y_train, y_test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used the help of this post to set up hyperparameter tuning with hyperopt: https://medium.com/@rehabreda/mlflow-hyperopt-prefect-evidently-and-grafana-the-ultimate-guide-to-building-tracking-2d3591b6c1bd\n",
    "@task\n",
    "def train_hyperparameter_tuning(X_train, X_test, y_train, y_test, model_name):\n",
    "    search_space = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 1001, 100)),\n",
    "    'max_depth': hp.choice('max_depth', range(3, 21, 3)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 11)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 11)),\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False])\n",
    "}\n",
    "\n",
    "\n",
    "    def objective (params):\n",
    "    \n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.set_tag(\"model\", \"randomforest\")\n",
    "            mlflow.log_params(params)\n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_test)\n",
    "            \n",
    "            mse = mean_squared_error(y_test,y_pred)\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            \n",
    "            mlflow.sklearn.log_model(\n",
    "                rf, artifact_path=\"mlruns\", \n",
    "                registered_model_name = model_name\n",
    "            )\n",
    "            \n",
    "        return {'loss': -mse, 'status': STATUS_OK } \n",
    "\n",
    "    \n",
    "    best_result = fmin(\n",
    "    fn = objective,\n",
    "    space = search_space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 5,\n",
    "    trials = Trials())\n",
    "\n",
    "    return best_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best model and send to production on mlflow\n",
    "@task\n",
    "def get_best_model(experiment_id):\n",
    "    client = MlflowClient(tracking_uri=\"http://34.171.118.161:5000\")\n",
    "    run = MlflowClient().search_runs(\n",
    "    experiment_ids = experiment_id,\n",
    "    run_view_type = ViewType.ACTIVE_ONLY,\n",
    "    order_by=[\"metrics.mse DESC\"]\n",
    "    )[0]\n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/mlruns\"\n",
    "    model_src = RunsArtifactRepository.get_underlying_uri(model_uri)\n",
    "\n",
    "    filter_string = \"run_id='{}'\".format(run_id)\n",
    "    results = client.search_model_versions(filter_string)\n",
    "    model_version=results[0].version\n",
    "\n",
    "    return model_version ,model_uri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model to production\n",
    "@task\n",
    "def promote_best_model(model_version,model_name):\n",
    "    new_stage = \"Production\"\n",
    "    client = MlflowClient(tracking_uri=\"http://34.171.118.161:5000\")\n",
    "    client.transition_model_version_stage(\n",
    "            name=model_name,\n",
    "            version=model_version,\n",
    "            stage=new_stage,\n",
    "            archive_existing_versions=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafana Dashboard with Docker (not set up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def container_status(container_names):\n",
    "#     client = docker.from_env()\n",
    "\n",
    "#     # Specify the prefix of the container name\n",
    "    \n",
    "#     running_containers=0\n",
    "\n",
    "#     for container_name in container_names :\n",
    "#         containers = client.containers.list(filters={\"name\": container_name})\n",
    "#         if len(containers)!=0:\n",
    "#             if client.api.inspect_container(containers[0].id)[\"State\"][\"Running\"]:\n",
    "#                 running_containers+=1\n",
    "#         time.sleep(1) \n",
    "     \n",
    "            \n",
    "\n",
    "#     client.close()  \n",
    "#     return running_containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task\n",
    "# def docker_up(container_names):\n",
    "#     #os.environ[\"COMPOSE_PROJECT_NAME\"] = container_name\n",
    "#     running_containers=container_status(container_names)\n",
    "#     if running_containers!=3 :\n",
    "#        os.system(\"start docker-compose up --build \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task\n",
    "# def wait_for_container(container_names):\n",
    "#     client = docker.from_env()\n",
    "\n",
    "#     # Specify the prefix of the container name\n",
    "\n",
    "#     for container_name in container_names :\n",
    "        \n",
    "#         while True:\n",
    "#             containers = client.containers.list(filters={\"name\": container_name})\n",
    "#             if len(containers)==1 and client.api.inspect_container(containers[0].id)[\"State\"][\"Running\"]:\n",
    "#                 break\n",
    "#             time.sleep(120)           \n",
    "#     client.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task\n",
    "# def prep_db():\n",
    "     \n",
    "#      create_table_statement = \"\"\"\n",
    "#         drop table if exists predictions_metrics;\n",
    "#         create table predictions_metrics(\n",
    "#             timestamp timestamp,\n",
    "#             prediction_drift float,\n",
    "#             num_drifted_columns integer,\n",
    "#             share_missing_values float\n",
    "#         )\n",
    "#      \"\"\"\n",
    "#      con = psycopg2.connect(host='localhost', user='postgres',password='example',database='postgres', port=5432)\n",
    "#      con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT) # <-- ADD THIS LINE\n",
    "#      cur = con.cursor()\n",
    "#      check_database_query = \"SELECT EXISTS(SELECT 1 FROM pg_database WHERE datname = 'test')\"\n",
    "#      # Execute the SQL statement to check if the database exists\n",
    "#      cur.execute(check_database_query)\n",
    "#      # Fetch the result of the query\n",
    "#      exists = cur.fetchone()[0]\n",
    "#      if not exists:\n",
    "#         cur.execute(sql.SQL(\"CREATE DATABASE  test\"))\n",
    "#      with psycopg2.connect(host='localhost', user='postgres',password='example', dbname='test', port=5432) as conn:\n",
    "#         cur = conn.cursor()        \n",
    "#         cur.execute(create_table_statement)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task\n",
    "# def prepare_reference_data(model_uri,x_train,x_test):\n",
    "#     loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "#     x_train['prediction'] = loaded_model.predict(x_train)\n",
    "#     engine = create_engine('postgresql+psycopg2://postgres:example@localhost:5432/test')\n",
    "#     x_train.to_sql('reference', con=engine, if_exists='replace',\n",
    "#           index=False)\n",
    "#     x_test.to_sql('production', con=engine, if_exists='replace',\n",
    "#           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def serve_model(model_uri):\n",
    "   os.system(\"start killport 8000 \")\n",
    "   os.system(f\"start uvicorn main:app  \") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow starting from downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow\n",
    "def main(experiment_name, model_name):\n",
    "    experiment_id = mlflow_environment(experiment_name)\n",
    "    # add data download and preparation\n",
    "    year = 2023\n",
    "    month = 4\n",
    "    \n",
    "    result = download_file(year, month)\n",
    "    print(result)\n",
    "    \n",
    "    #download_data(year, month)\n",
    "    path_output, filename_output = prepare_dataset(year, month) # creates usage set - save into parquet\n",
    "\n",
    "    usage_data_file = filename_output\n",
    "    print(usage_data_file)\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        #preprocess_data load the usage dataset\n",
    "        \n",
    "        split_params = {\"test_size\": 0.2, \"random_state\": 42}\n",
    "        mlflow.log_param(\"split_params\", split_params)\n",
    "\n",
    "        ohe, scaler, transformed_X_train, transformed_X_test, y_train, y_test = preprocess_data(usage_data_file, split_params)\n",
    "        mlflow.log_param(\"usage_data_file\", usage_data_file)\n",
    "\n",
    "        encoder_scaler_filename = f'encoder_scaler-{experiment_name}-{experiment_id}.pkl'\n",
    "        save_encoder_scaler(ohe, scaler, encoder_scaler_filename)\n",
    "\n",
    "        with open(f\"models/encoder-{experiment_name}-{experiment_id}.pkl\", \"wb\") as f:\n",
    "             pickle.dump(ohe, f)\n",
    "        mlflow.log_artifact(f\"models/encoder-{experiment_name}-{experiment_id}.pkl\")\n",
    "    \n",
    "        with open(f\"./models/scaler-{experiment_name}-{experiment_id}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        \n",
    "        mlflow.log_artifact(f\"./models/scaler-{experiment_name}-{experiment_id}.pkl\")\n",
    "\n",
    "        # #saving sets locally\n",
    "        # with open(f'../data/test_data/202304-usage-{experiment_name}-{experiment_id}.pkl', 'wb') as f:\n",
    "        #     pickle.dump((transformed_X_train, y_train, transformed_X_test, y_test), f)\n",
    "        # transformed_test = pd.concat([transformed_X_test, y_test], axis =1)\n",
    "        # transformed_test.to_parquet(f\"../deployment/data/202304-transformed_X_test-{experiment_name}-{experiment_id}.parquet\")\n",
    "\n",
    "        #saving data to GCS\n",
    "        train_test_filename= f'202304-usage-{experiment_name}-{experiment_id}.pkl'\n",
    "        test_filename = f'202304-transformed_X_test-{experiment_name}-{experiment_id}.parquet'\n",
    "        \n",
    "        save_dataframes_gcs(transformed_X_train, y_train, transformed_X_test, y_test, train_test_filename, test_filename)\n",
    "\n",
    "        best_result = train_hyperparameter_tuning(transformed_X_train,transformed_X_test, y_train, y_test, model_name)\n",
    "        \n",
    "        print(experiment_id)\n",
    "        \n",
    "        model_version, model_uri = get_best_model(experiment_id)\n",
    "\n",
    "        print(model_version)\n",
    "        print(model_uri)\n",
    "\n",
    "        #os.environ['model_uri'] = model_uri\n",
    "        \n",
    "        promote_best_model(model_version, model_name)\n",
    "\n",
    "        #docker_up(container_names)\n",
    "        #prep_db()\n",
    "        #prepare_reference_data(model_uri, transformed_X_train, transformed_X_test)\n",
    "        #serve_model(model_uri)\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:54.823 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'main'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:54.823 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'lush-agama'\u001b[0m for flow\u001b[1;35m 'main'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:54.829 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://app.prefect.cloud/account/9a75fb5e-0068-4107-b908-7b1971037227/workspace/28c4637d-cdf0-4ac8-9a7b-138a3a8e9a50/flow-runs/flow-run/27229ece-fd02-42db-8fd3-daaff18d95b8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:54.829 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - View at \u001b[94mhttps://app.prefect.cloud/account/9a75fb5e-0068-4107-b908-7b1971037227/workspace/28c4637d-cdf0-4ac8-9a7b-138a3a8e9a50/flow-runs/flow-run/27229ece-fd02-42db-8fd3-daaff18d95b8\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:55.623 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Created task run 'mlflow_environment-0' for task 'mlflow_environment'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:55.623 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Created task run 'mlflow_environment-0' for task 'mlflow_environment'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:55.626 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Executing 'mlflow_environment-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:55.626 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Executing 'mlflow_environment-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://34.171.118.161:5000'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:56.460 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'mlflow_environment-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:56.460 | \u001b[36mINFO\u001b[0m    | Task run 'mlflow_environment-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:56.618 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Created task run 'download_file-0' for task 'download_file'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:56.618 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Created task run 'download_file-0' for task 'download_file'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:56.620 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Executing 'download_file-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:56.620 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Executing 'download_file-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202304:   0%|          | 15038/15398190 [00:01<19:02, 13462.27it/s, save to ./data/raw/202304.zip]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:59.042 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'download_file-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:59.042 | \u001b[36mINFO\u001b[0m    | Task run 'download_file-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': './data/raw/202304-divvy-tripdata.csv', 'year': 2023, 'month': '04'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:59.216 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Created task run 'prepare_dataset-0' for task 'prepare_dataset'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:59.216 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Created task run 'prepare_dataset-0' for task 'prepare_dataset'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:25:59.219 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Executing 'prepare_dataset-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:25:59.219 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Executing 'prepare_dataset-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:03.516 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'prepare_dataset-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:03.516 | \u001b[36mINFO\u001b[0m    | Task run 'prepare_dataset-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/processed/202304-usage.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:03.896 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Created task run 'preprocess_data-0' for task 'preprocess_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:03.896 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Created task run 'preprocess_data-0' for task 'preprocess_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:03.899 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Executing 'preprocess_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:03.899 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Executing 'preprocess_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:04.481 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Created task run 'encode_categorical-0' for task 'encode_categorical'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:04.481 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Created task run 'encode_categorical-0' for task 'encode_categorical'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:04.483 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Executing 'encode_categorical-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:04.483 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Executing 'encode_categorical-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:06.861 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'encode_categorical-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:06.861 | \u001b[36mINFO\u001b[0m    | Task run 'encode_categorical-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:07.043 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Created task run 'split_data-0' for task 'split_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:07.043 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Created task run 'split_data-0' for task 'split_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:07.045 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Executing 'split_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:07.045 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Executing 'split_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:08.596 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:08.596 | \u001b[36mINFO\u001b[0m    | Task run 'split_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:08.771 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Created task run 'scale_numerical-0' for task 'scale_numerical'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:08.771 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Created task run 'scale_numerical-0' for task 'scale_numerical'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:08.774 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Executing 'scale_numerical-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:08.774 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Executing 'scale_numerical-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:11.137 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'scale_numerical-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:11.137 | \u001b[36mINFO\u001b[0m    | Task run 'scale_numerical-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:11.322 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:11.322 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:11.574 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Created task run 'save_encoder_scaler-0' for task 'save_encoder_scaler'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:11.574 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Created task run 'save_encoder_scaler-0' for task 'save_encoder_scaler'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:11.577 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Executing 'save_encoder_scaler-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:11.577 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Executing 'save_encoder_scaler-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:15.232 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'save_encoder_scaler-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:15.232 | \u001b[36mINFO\u001b[0m    | Task run 'save_encoder_scaler-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:17.613 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Created task run 'save_dataframes_gcs-0' for task 'save_dataframes_gcs'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:17.613 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Created task run 'save_dataframes_gcs-0' for task 'save_dataframes_gcs'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:26:17.617 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Executing 'save_dataframes_gcs-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:26:17.617 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Executing 'save_dataframes_gcs-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:29:49.897 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'save_dataframes_gcs-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:29:49.897 | \u001b[36mINFO\u001b[0m    | Task run 'save_dataframes_gcs-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:29:50.205 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Created task run 'train_hyperparameter_tuning-0' for task 'train_hyperparameter_tuning'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:29:50.205 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Created task run 'train_hyperparameter_tuning-0' for task 'train_hyperparameter_tuning'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:29:50.208 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lush-agama'</span> - Executing 'train_hyperparameter_tuning-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:29:50.208 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'lush-agama'\u001b[0m - Executing 'train_hyperparameter_tuning-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/14 11:46:05 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [16:15<1:05:00, 975.12s/trial, best loss: -21.26065831272915]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'random-forest-regressor'.\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/14 11:51:22 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 8\n",
      "\n",
      "Created version '8' of model 'random-forest-regressor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [21:31<29:22, 587.62s/trial, best loss: -22.00827221350515]  "
     ]
    }
   ],
   "source": [
    "#testing flow from raw data\n",
    "experiment_name = '08142024'\n",
    "model_name = 'random-forest-regressor'\n",
    "main(experiment_name, model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow starting from prepared dataset - working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@flow\n",
    "def main(experiment_name, model_name):\n",
    "    experiment_id = mlflow_environment(experiment_name)\n",
    "    with mlflow.start_run(nested=True):\n",
    "        data_file = \"../data/processed/202304-usage.parquet\" \n",
    "        df = load_prepared_data(data_file)\n",
    "        mlflow.log_param(\"data_file\", data_file)\n",
    "        \n",
    "        # categorical encode\n",
    "        ohe, encoded_df = encode_categorical(df)\n",
    "        with open(f\"models/encoder-{experiment_name}-{experiment_id}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(ohe, f)\n",
    "        mlflow.log_artifact(f\"models/encoder-{experiment_name}-{experiment_id}.pkl\")\n",
    "\n",
    "        #split sets\n",
    "        split_params = {\"test_size\": 0.2, \"random_state\": 42}\n",
    "        X_train, X_test, y_train, y_test = split_data(encoded_df, split_params)\n",
    "        mlflow.log_param(\"split_params\", split_params)\n",
    "\n",
    "        #numerical scale\n",
    "        scaler, transformed_X_train, transformed_X_test, y_train, y_test = scale_numerical(X_train, X_test, y_train, y_test)\n",
    "        with open(f\"./models/scaler-{experiment_name}-{experiment_id}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        mlflow.log_artifact(f\"./models/scaler-{experiment_name}-{experiment_id}.pkl\")\n",
    "\n",
    "        \n",
    "        #saving sets\n",
    "        with open(f'../data/test_data/202304-usage-{experiment_name}-{experiment_id}.pkl', 'wb') as f:\n",
    "            pickle.dump((transformed_X_train, y_train, transformed_X_test, y_test), f)\n",
    "        transformed_test = pd.concat([transformed_X_test, y_test], axis =1)\n",
    "        transformed_test.to_parquet(f\"../deployment/data/202304-transformed_X_test-{experiment_name}-{experiment_id}.parquet\")\n",
    "\n",
    "        #saving data to GCS\n",
    "        train_test_filename= f'202304-usage-{experiment_name}-{experiment_id}.pkl'\n",
    "        test_filename = f'202304-transformed_X_test-{experiment_name}-{experiment_id}.parquet'\n",
    "        save_dataframes_gcs(transformed_X_train, y_train, transformed_X_test, y_test, train_test_filename, test_filename)\n",
    "\n",
    "\n",
    "        best_result = train_hyperparameter_tuning(transformed_X_train,transformed_X_test, y_train, y_test, model_name)\n",
    "        \n",
    "        print(experiment_id)\n",
    "        \n",
    "        model_version, model_uri = get_best_model(experiment_id)\n",
    "\n",
    "        print(model_version)\n",
    "        print(model_uri)\n",
    "\n",
    "        #os.environ['model_uri'] = model_uri\n",
    "        \n",
    "        promote_best_model(model_version, model_name)\n",
    "\n",
    "        #docker_up(container_names)\n",
    "        #prep_db()\n",
    "        #prepare_reference_data(model_uri, transformed_X_train, transformed_X_test)\n",
    "        #serve_model(model_uri)\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name ='experiment-20240813'\n",
    "model_name = \"random-forest-regressor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:02.241 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'main'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:02.241 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'sepia-lemming'\u001b[0m for flow\u001b[1;35m 'main'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:02.252 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://app.prefect.cloud/account/9a75fb5e-0068-4107-b908-7b1971037227/workspace/28c4637d-cdf0-4ac8-9a7b-138a3a8e9a50/flow-runs/flow-run/6083ea94-84d8-4c7d-8fda-d4068165f48a</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:02.252 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - View at \u001b[94mhttps://app.prefect.cloud/account/9a75fb5e-0068-4107-b908-7b1971037227/workspace/28c4637d-cdf0-4ac8-9a7b-138a3a8e9a50/flow-runs/flow-run/6083ea94-84d8-4c7d-8fda-d4068165f48a\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:02.709 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'mlflow_environment-0' for task 'mlflow_environment'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:02.709 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'mlflow_environment-0' for task 'mlflow_environment'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:02.713 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'mlflow_environment-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:02.713 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'mlflow_environment-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://34.171.118.161:5000'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:03.437 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'mlflow_environment-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:03.437 | \u001b[36mINFO\u001b[0m    | Task run 'mlflow_environment-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:03.740 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'load_prepared_data-0' for task 'load_prepared_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:03.740 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'load_prepared_data-0' for task 'load_prepared_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:03.741 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'load_prepared_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:03.741 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'load_prepared_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:04.296 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_prepared_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:04.296 | \u001b[36mINFO\u001b[0m    | Task run 'load_prepared_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:16.181 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'save_dataframes_gcs-0' for task 'save_dataframes_gcs'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:16.181 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'save_dataframes_gcs-0' for task 'save_dataframes_gcs'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:16.187 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'save_dataframes_gcs-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:16.187 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'save_dataframes_gcs-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:06:59.327 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'save_dataframes_gcs-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:06:59.327 | \u001b[36mINFO\u001b[0m    | Task run 'save_dataframes_gcs-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:06:59.539 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'train_hyperparameter_tuning-0' for task 'train_hyperparameter_tuning'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:06:59.539 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'train_hyperparameter_tuning-0' for task 'train_hyperparameter_tuning'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:06:59.541 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'train_hyperparameter_tuning-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:06:59.541 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'train_hyperparameter_tuning-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 12:11:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [04:24<17:38, 264.62s/trial, best loss: -21.826912973684998]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'random-forest-regressor'.\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 12:26:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [19:53<32:45, 655.23s/trial, best loss: -21.922722686254843]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'random-forest-regressor'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:42:49.912 | <span style=\"color: #d7d700; text-decoration-color: #d7d700\">WARNING</span> | urllib3.connectionpool - Retrying (Retry(total=4, connect=4, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x1643d9850&gt;: <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span> to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:42:49.912 | \u001b[38;5;184mWARNING\u001b[0m | urllib3.connectionpool - Retrying (Retry(total=4, connect=4, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1643d9850>: \u001b[38;5;160mFailed\u001b[0m to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:42:54.118 | <span style=\"color: #d7d700; text-decoration-color: #d7d700\">WARNING</span> | urllib3.connectionpool - Retrying (Retry(total=3, connect=3, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x170098050&gt;: <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span> to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:42:54.118 | \u001b[38;5;184mWARNING\u001b[0m | urllib3.connectionpool - Retrying (Retry(total=3, connect=3, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x170098050>: \u001b[38;5;160mFailed\u001b[0m to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:43:02.273 | <span style=\"color: #d7d700; text-decoration-color: #d7d700\">WARNING</span> | urllib3.connectionpool - Retrying (Retry(total=2, connect=2, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x16fd4e850&gt;: <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span> to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:43:02.273 | \u001b[38;5;184mWARNING\u001b[0m | urllib3.connectionpool - Retrying (Retry(total=2, connect=2, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x16fd4e850>: \u001b[38;5;160mFailed\u001b[0m to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:02:53.902 | <span style=\"color: #d7d700; text-decoration-color: #d7d700\">WARNING</span> | urllib3.connectionpool - Retrying (Retry(total=1, connect=1, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x1701c7790&gt;: <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span> to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:02:53.902 | \u001b[38;5;184mWARNING\u001b[0m | urllib3.connectionpool - Retrying (Retry(total=1, connect=1, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1701c7790>: \u001b[38;5;160mFailed\u001b[0m to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 14:03:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [1:56:25<1:40:02, 3001.04s/trial, best loss: -21.99691175885226]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '4' of model 'random-forest-regressor'.\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 14:24:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [2:17:30<38:35, 2315.34s/trial, best loss: -22.074096583710904] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '5' of model 'random-forest-regressor'.\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 14:26:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 6\n",
      "\n",
      "Created version '6' of model 'random-forest-regressor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [2:19:54<00:00, 1678.82s/trial, best loss: -22.074096583710904]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:54.636 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_hyperparameter_tuning-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:54.636 | \u001b[36mINFO\u001b[0m    | Task run 'train_hyperparameter_tuning-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:54.817 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'get_best_model-0' for task 'get_best_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:54.817 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'get_best_model-0' for task 'get_best_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:54.825 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'get_best_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:54.825 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'get_best_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:55.626 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'get_best_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:55.626 | \u001b[36mINFO\u001b[0m    | Task run 'get_best_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "runs:/1290d94d659f4f6da4202bec8927c2be/mlruns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:55.811 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'promote_best_model-0' for task 'promote_best_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:55.811 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'promote_best_model-0' for task 'promote_best_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:55.814 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'promote_best_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:55.814 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'promote_best_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/nb8m5vwd1sz3_s49jh1plcfr0000gn/T/ipykernel_10805/1789494125.py:6: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:56.367 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'promote_best_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:56.367 | \u001b[36mINFO\u001b[0m    | Task run 'promote_best_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:56.720 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:56.720 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `str`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `DataFrame`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `dict`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `tuple`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`'))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(experiment_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
