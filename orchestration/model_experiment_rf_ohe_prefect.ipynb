{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from prefect import flow, task\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "\n",
    "import evidently\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils imports\n",
    "from utils.get_data.download_data import download_file\n",
    "from utils.data_preprocessing.data_preparation import load_dataframe, remove_missing_data, create_hour_weekday, transform_df_target, extract_station_info\n",
    "from utils.data_processing.feature_encode_scale import encode_categorical, scale_numerical\n",
    "from utils.data_processing.splitter import split_data\n",
    "from utils.save_data.save_to_gcs import save_multiple_dataframes_to_gcs_as_pkl, save_dataframe_to_gcs_as_parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download raw data, preprocess and create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_multiple_pkl_to_gcs(encoder_scaler, bucket_name, folder_path, file_name):\n",
    "    with io.BytesIO() as buffer:\n",
    "        pickle.dump(encoder_scaler, buffer)\n",
    "        buffer.seek(0)\n",
    "\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(f\"{folder_path}/{file_name}.pkl\")\n",
    "        blob.upload_from_file(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up mlflow experiment on prefect (https://medium.com/@rehabreda/mlflow-hyperopt-prefect-evidently-and-grafana-the-ultimate-guide-to-building-tracking-2d3591b6c1bd)\n",
    " \n",
    "@task\n",
    "def mlflow_environment(experiment_name):\n",
    "    TRACKING_SERVER_HOST = \"34.171.118.161\" #external IP reserved in GCP - updated Aug 8 2024\n",
    "    mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\") \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")\n",
    "\n",
    "    return experiment.experiment_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data and prepare data\n",
    "# @task\n",
    "# def download_data(year, month):\n",
    "    \n",
    "#     result = download_file(year, month)\n",
    "#     print(f'Downloaded file is available at {result[\"path\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def download_file(year, month):\n",
    "    month = str(month).zfill(2)\n",
    "    file= f'{year}{month}' #change to env variables year and month and path\n",
    "    path= './data/raw'\n",
    "    url=f'https://divvy-tripdata.s3.amazonaws.com/{file}-divvy-tripdata.zip'\n",
    "\n",
    "    resp=requests.get(url, stream=True)\n",
    "    zip_save_path = f'{path}/{file}.zip'\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    with open(zip_save_path,\"wb\") as handle:\n",
    "        for data in tqdm(resp.iter_content(chunk_size=1024),\n",
    "                        desc=f'{file}',\n",
    "                        postfix=f\"save to {zip_save_path}\",\n",
    "                        total=int(resp.headers[\"Content-Length\"])):\n",
    "            handle.write(data)\n",
    "\n",
    "    with zipfile.ZipFile(zip_save_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "    \n",
    "    os.remove(zip_save_path)\n",
    "\n",
    "    return {\n",
    "      \"path\": f'{path}/{year}{month}-divvy-tripdata.csv',\n",
    "      \"year\": year,\n",
    "      \"month\": month\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def prepare_dataset(year, month):\n",
    "    month = str(month).zfill(2)\n",
    "    path_input ='./data/raw'   \n",
    "    path_output ='./data/processed'\n",
    "    filename_input = f'{path_input}/{year}{month}-divvy-tripdata.csv'\n",
    "    filename_output = f'{path_output}/{year}{month}-usage.parquet'\n",
    "\n",
    "    df = load_dataframe(filename_input) \n",
    "    df = remove_missing_data(df)\n",
    "    df = create_hour_weekday(df)\n",
    "\n",
    "    usage_df = transform_df_target(df)\n",
    "\n",
    "    usage_df_final = extract_station_info(usage_df.copy())\n",
    "\n",
    "    usage_df_final.to_parquet(filename_output)\n",
    "\n",
    "    return usage_df_final, filename_output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, data processing and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def preprocess_data(data_file, split_params):\n",
    "    df = pd.read_parquet(data_file)\n",
    "    ohe, encoded_df = encode_categorical(df)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(encoded_df, split_params)\n",
    "\n",
    "    scaler, transformed_X_train, transformed_X_test, y_train, y_test = scale_numerical(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    return ohe, scaler, transformed_X_train, transformed_X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def save_dataframes_gcs(usage_df_final, transformed_X_train, y_train, transformed_X_test, y_test, usage_filename, train_test_filename, test_filename):\n",
    "    bucket_name = 'mlops-divvy-experiment-tracking'\n",
    "    folder_path ='data/deployment'\n",
    "\n",
    "    save_dataframe_to_gcs_as_parquet(usage_df_final, bucket_name, folder_path, usage_filename)\n",
    "\n",
    "    dataframes =[transformed_X_train, y_train, transformed_X_test, y_test]\n",
    "\n",
    "    save_multiple_dataframes_to_gcs_as_pkl(dataframes, bucket_name, folder_path, train_test_filename)\n",
    "\n",
    "    transformed_test = pd.concat([transformed_X_test, y_test], axis =1)\n",
    "    save_dataframe_to_gcs_as_parquet(transformed_test, bucket_name, folder_path, test_filename)\n",
    "\n",
    "    print(f'transformed training and test sets saved in pkl, transformed set saved as parquet to deployment folder ')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def save_encoder_scaler(ohe, scaler,file_name):\n",
    "    encoder_scaler = [ohe, scaler]\n",
    "    bucket_name = 'mlops-divvy-experiment-tracking'\n",
    "    folder_path ='models/deployment'\n",
    "\n",
    "    save_multiple_pkl_to_gcs(encoder_scaler, bucket_name, folder_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def save_experiment_data(transformed_X_train,y_train, transformed_X_test, y_test, train_test_path, test_path):\n",
    "    with open(train_test_path, 'wb') as f: \n",
    "            pickle.dump((transformed_X_train, y_train, transformed_X_test, y_test), f)\n",
    "    transformed_test = pd.concat([transformed_X_test, y_test], axis =1)\n",
    "    transformed_test.to_parquet(test_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading daat function and task\n",
    "@task\n",
    "def load_prepared_data(data_file): \n",
    "    df = pd.read_parquet(data_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical data\n",
    "@task\n",
    "def encode_categorical(df):\n",
    "    cat_features = ['station_name', 'day_of_week']\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    ohe_cols = pd.DataFrame(ohe.fit_transform(df[cat_features]).toarray(), columns = ohe.get_feature_names_out(cat_features))\n",
    "    ohe_cols.index = df.index\n",
    "\n",
    "    encoded_df = pd.concat([df, ohe_cols], axis=1)\n",
    "    encoded_df = encoded_df.drop(cat_features, axis =1)\n",
    "\n",
    "    return ohe, encoded_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "@task\n",
    "def split_data(df, params):\n",
    "    features = df.drop(['net_usage'], axis =1)\n",
    "    target = df['net_usage']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, **params)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def scale_numerical(X_train, X_test, y_train, y_test):\n",
    "    num_features= ['hour']\n",
    "    Standard_Scaler = StandardScaler()\n",
    "    num_scaled_train = pd.DataFrame(Standard_Scaler.fit_transform(X_train[num_features]), columns=['hour_scaled'])\n",
    "    num_scaled_test = pd.DataFrame(Standard_Scaler.transform(X_test[num_features]), columns=['hour_scaled'])\n",
    "\n",
    "    num_scaled_train.index = X_train.index\n",
    "    num_scaled_test.index = X_test.index\n",
    "\n",
    "    scaled_X_train = pd.concat([X_train, num_scaled_train], axis=1)\n",
    "    scaled_X_test = pd.concat([X_test, num_scaled_test], axis=1)\n",
    "\n",
    "    scaled_X_train = scaled_X_train.drop(num_features, axis=1)\n",
    "    scaled_X_test = scaled_X_test.drop(num_features, axis=1)\n",
    "\n",
    "    return Standard_Scaler, scaled_X_train, scaled_X_test, y_train, y_test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used the help of this post to set up hyperparameter tuning with hyperopt: https://medium.com/@rehabreda/mlflow-hyperopt-prefect-evidently-and-grafana-the-ultimate-guide-to-building-tracking-2d3591b6c1bd\n",
    "@task\n",
    "def train_hyperparameter_tuning(X_train, X_test, y_train, y_test, model_name):\n",
    "    search_space = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 1001, 100)),\n",
    "    'max_depth': hp.choice('max_depth', range(3, 21, 3)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 11)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 11)),\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False])\n",
    "}\n",
    "\n",
    "\n",
    "    def objective (params):\n",
    "    \n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.set_tag(\"model\", \"randomforest\")\n",
    "            mlflow.log_params(params)\n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_test)\n",
    "            \n",
    "            mse = mean_squared_error(y_test,y_pred)\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            \n",
    "            mlflow.sklearn.log_model(\n",
    "                rf, artifact_path=\"mlruns\", \n",
    "                registered_model_name = model_name\n",
    "            )\n",
    "            \n",
    "        return {'loss': -mse, 'status': STATUS_OK } \n",
    "\n",
    "    \n",
    "    best_result = fmin(\n",
    "    fn = objective,\n",
    "    space = search_space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 5,\n",
    "    trials = Trials())\n",
    "\n",
    "    return best_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best model and send to production on mlflow\n",
    "@task\n",
    "def get_best_model(experiment_id):\n",
    "    client = MlflowClient(tracking_uri=\"http://34.171.118.161:5000\")\n",
    "    run = MlflowClient().search_runs(\n",
    "    experiment_ids = experiment_id,\n",
    "    run_view_type = ViewType.ACTIVE_ONLY,\n",
    "    order_by=[\"metrics.mse DESC\"]\n",
    "    )[0]\n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/mlruns\"\n",
    "    model_src = RunsArtifactRepository.get_underlying_uri(model_uri)\n",
    "\n",
    "    filter_string = \"run_id='{}'\".format(run_id)\n",
    "    results = client.search_model_versions(filter_string)\n",
    "    model_version=results[0].version\n",
    "\n",
    "    return model_version ,model_uri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model to production\n",
    "@task\n",
    "def promote_best_model(model_version,model_name):\n",
    "    new_stage = \"Production\"\n",
    "    client = MlflowClient(tracking_uri=\"http://34.171.118.161:5000\")\n",
    "    client.transition_model_version_stage(\n",
    "            name=model_name,\n",
    "            version=model_version,\n",
    "            stage=new_stage,\n",
    "            archive_existing_versions=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafana Dashboard with Docker (not set up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def container_status(container_names):\n",
    "#     client = docker.from_env()\n",
    "\n",
    "#     # Specify the prefix of the container name\n",
    "    \n",
    "#     running_containers=0\n",
    "\n",
    "#     for container_name in container_names :\n",
    "#         containers = client.containers.list(filters={\"name\": container_name})\n",
    "#         if len(containers)!=0:\n",
    "#             if client.api.inspect_container(containers[0].id)[\"State\"][\"Running\"]:\n",
    "#                 running_containers+=1\n",
    "#         time.sleep(1) \n",
    "     \n",
    "            \n",
    "\n",
    "#     client.close()  \n",
    "#     return running_containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task\n",
    "# def docker_up(container_names):\n",
    "#     #os.environ[\"COMPOSE_PROJECT_NAME\"] = container_name\n",
    "#     running_containers=container_status(container_names)\n",
    "#     if running_containers!=3 :\n",
    "#        os.system(\"start docker-compose up --build \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task\n",
    "# def wait_for_container(container_names):\n",
    "#     client = docker.from_env()\n",
    "\n",
    "#     # Specify the prefix of the container name\n",
    "\n",
    "#     for container_name in container_names :\n",
    "        \n",
    "#         while True:\n",
    "#             containers = client.containers.list(filters={\"name\": container_name})\n",
    "#             if len(containers)==1 and client.api.inspect_container(containers[0].id)[\"State\"][\"Running\"]:\n",
    "#                 break\n",
    "#             time.sleep(120)           \n",
    "#     client.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task\n",
    "# def prep_db():\n",
    "     \n",
    "#      create_table_statement = \"\"\"\n",
    "#         drop table if exists predictions_metrics;\n",
    "#         create table predictions_metrics(\n",
    "#             timestamp timestamp,\n",
    "#             prediction_drift float,\n",
    "#             num_drifted_columns integer,\n",
    "#             share_missing_values float\n",
    "#         )\n",
    "#      \"\"\"\n",
    "#      con = psycopg2.connect(host='localhost', user='postgres',password='example',database='postgres', port=5432)\n",
    "#      con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT) # <-- ADD THIS LINE\n",
    "#      cur = con.cursor()\n",
    "#      check_database_query = \"SELECT EXISTS(SELECT 1 FROM pg_database WHERE datname = 'test')\"\n",
    "#      # Execute the SQL statement to check if the database exists\n",
    "#      cur.execute(check_database_query)\n",
    "#      # Fetch the result of the query\n",
    "#      exists = cur.fetchone()[0]\n",
    "#      if not exists:\n",
    "#         cur.execute(sql.SQL(\"CREATE DATABASE  test\"))\n",
    "#      with psycopg2.connect(host='localhost', user='postgres',password='example', dbname='test', port=5432) as conn:\n",
    "#         cur = conn.cursor()        \n",
    "#         cur.execute(create_table_statement)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task\n",
    "# def prepare_reference_data(model_uri,x_train,x_test):\n",
    "#     loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "#     x_train['prediction'] = loaded_model.predict(x_train)\n",
    "#     engine = create_engine('postgresql+psycopg2://postgres:example@localhost:5432/test')\n",
    "#     x_train.to_sql('reference', con=engine, if_exists='replace',\n",
    "#           index=False)\n",
    "#     x_test.to_sql('production', con=engine, if_exists='replace',\n",
    "#           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def serve_model(model_uri):\n",
    "   os.system(\"start killport 8000 \")\n",
    "   os.system(f\"start uvicorn main:app  \") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow starting from downloading the raw data - WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@flow\n",
    "def main(experiment_name, model_name):\n",
    "    experiment_id = mlflow_environment(experiment_name)\n",
    "    # add data download and preparation\n",
    "    year = 2023\n",
    "    month = 4\n",
    "    \n",
    "    result = download_file(year, month)\n",
    "    print(result)\n",
    "    \n",
    "    usage_df_final, filename_output = prepare_dataset(year, month)\n",
    "    print('dataset usage to train is ready!')\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        #preprocess_data load the usage dataset\n",
    "        \n",
    "        split_params = {\"test_size\": 0.2, \"random_state\": 42}\n",
    "        mlflow.log_param(\"split_params\", split_params)\n",
    "\n",
    "        ohe, scaler, transformed_X_train, transformed_X_test, y_train, y_test = preprocess_data(filename_output, split_params)\n",
    "        mlflow.log_param(\"usage_data_file\", filename_output)\n",
    "\n",
    "        encoder_scaler_filename = f'encoder_scaler-{experiment_name}-{experiment_id}.pkl'\n",
    "        save_encoder_scaler(ohe, scaler, encoder_scaler_filename)\n",
    "\n",
    "        with open(f\"models/encoder-{experiment_name}-{experiment_id}.pkl\", \"wb\") as f:\n",
    "             pickle.dump(ohe, f)\n",
    "        mlflow.log_artifact(f\"models/encoder-{experiment_name}-{experiment_id}.pkl\")\n",
    "    \n",
    "        with open(f\"./models/scaler-{experiment_name}-{experiment_id}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        \n",
    "        mlflow.log_artifact(f\"./models/scaler-{experiment_name}-{experiment_id}.pkl\")\n",
    "\n",
    "        # #saving sets locally\n",
    "        # with open(f'../data/test_data/202304-usage-{experiment_name}-{experiment_id}.pkl', 'wb') as f:\n",
    "        #     pickle.dump((transformed_X_train, y_train, transformed_X_test, y_test), f)\n",
    "        # transformed_test = pd.concat([transformed_X_test, y_test], axis =1)\n",
    "        # transformed_test.to_parquet(f\"../deployment/data/202304-transformed_X_test-{experiment_name}-{experiment_id}.parquet\")\n",
    "\n",
    "        #saving data to GCS\n",
    "        train_test_filename= f'202304-usage-{experiment_name}-{experiment_id}.pkl'\n",
    "        test_filename = f'202304-transformed_X_test-{experiment_name}-{experiment_id}.parquet'\n",
    "        usage_filename =f'{year}{month}-usage.parquet'\n",
    "\n",
    "        \n",
    "        save_dataframes_gcs(usage_df_final,transformed_X_train, y_train, transformed_X_test, y_test, usage_filename, train_test_filename, test_filename)\n",
    "\n",
    "        best_result = train_hyperparameter_tuning(transformed_X_train,transformed_X_test, y_train, y_test, model_name)\n",
    "        \n",
    "        print(experiment_id)\n",
    "        \n",
    "        model_version, model_uri = get_best_model(experiment_id)\n",
    "\n",
    "        print(model_version)\n",
    "        print(model_uri)\n",
    "\n",
    "        #os.environ['model_uri'] = model_uri\n",
    "        \n",
    "        promote_best_model(model_version, model_name)\n",
    "\n",
    "        #docker_up(container_names)\n",
    "        #prep_db()\n",
    "        #prepare_reference_data(model_uri, transformed_X_train, transformed_X_test)\n",
    "        #serve_model(model_uri)\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:37.225 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'main'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:37.225 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'hungry-copperhead'\u001b[0m for flow\u001b[1;35m 'main'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:37.235 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://app.prefect.cloud/account/9a75fb5e-0068-4107-b908-7b1971037227/workspace/28c4637d-cdf0-4ac8-9a7b-138a3a8e9a50/flow-runs/flow-run/28742f52-52c8-4c23-b1de-0611fbdd6f9c</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:37.235 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'hungry-copperhead'\u001b[0m - View at \u001b[94mhttps://app.prefect.cloud/account/9a75fb5e-0068-4107-b908-7b1971037227/workspace/28c4637d-cdf0-4ac8-9a7b-138a3a8e9a50/flow-runs/flow-run/28742f52-52c8-4c23-b1de-0611fbdd6f9c\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:37.625 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> - Created task run 'mlflow_environment-0' for task 'mlflow_environment'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:37.625 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'hungry-copperhead'\u001b[0m - Created task run 'mlflow_environment-0' for task 'mlflow_environment'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:37.629 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> - Executing 'mlflow_environment-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:37.629 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'hungry-copperhead'\u001b[0m - Executing 'mlflow_environment-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://34.171.118.161:5000'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:38.223 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'mlflow_environment-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:38.223 | \u001b[36mINFO\u001b[0m    | Task run 'mlflow_environment-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:38.398 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> - Created task run 'download_file-0' for task 'download_file'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:38.398 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'hungry-copperhead'\u001b[0m - Created task run 'download_file-0' for task 'download_file'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:38.400 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> - Executing 'download_file-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:38.400 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'hungry-copperhead'\u001b[0m - Executing 'download_file-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202304:   0%|          | 15038/15398190 [00:01<19:38, 13056.77it/s, save to ./data/raw/202304.zip]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:41.013 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'download_file-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:41.013 | \u001b[36mINFO\u001b[0m    | Task run 'download_file-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': './data/raw/202304-divvy-tripdata.csv', 'year': 2023, 'month': '04'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:41.194 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> - Created task run 'prepare_dataset-0' for task 'prepare_dataset'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:41.194 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'hungry-copperhead'\u001b[0m - Created task run 'prepare_dataset-0' for task 'prepare_dataset'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:41.196 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> - Executing 'prepare_dataset-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:41.196 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'hungry-copperhead'\u001b[0m - Executing 'prepare_dataset-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:45.445 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'prepare_dataset-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:45.445 | \u001b[36mINFO\u001b[0m    | Task run 'prepare_dataset-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:45.497 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> - Encountered exception during execution:\n",
       "Traceback (most recent call last):\n",
       "  File \"/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/engine.py\", line 877, in orchestrate_flow_run\n",
       "    result = await flow_call.aresult()\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n",
       "    return await asyncio.wrap_future(self.future)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n",
       "    result = self.fn(*self.args, **self.kwargs)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/var/folders/dd/nb8m5vwd1sz3_s49jh1plcfr0000gn/T/ipykernel_41097/1373901301.py\", line 11, in main\n",
       "    usage_df_final, filename_output = prepare_dataset(year, month)\n",
       "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "ValueError: too many values to unpack (expected 2)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:45.497 | \u001b[38;5;160mERROR\u001b[0m   | Flow run\u001b[35m 'hungry-copperhead'\u001b[0m - Encountered exception during execution:\n",
       "Traceback (most recent call last):\n",
       "  File \"/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/engine.py\", line 877, in orchestrate_flow_run\n",
       "    result = await flow_call.aresult()\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n",
       "    return await asyncio.wrap_future(self.future)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n",
       "    result = self.fn(*self.args, **self.kwargs)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/var/folders/dd/nb8m5vwd1sz3_s49jh1plcfr0000gn/T/ipykernel_41097/1373901301.py\", line 11, in main\n",
       "    usage_df_final, filename_output = prepare_dataset(year, month)\n",
       "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "ValueError: too many values to unpack (expected 2)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:13:45.634 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'hungry-copperhead'</span> - Finished in state <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span>('Flow run encountered an exception. ValueError: too many values to unpack (expected 2)')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:13:45.634 | \u001b[38;5;160mERROR\u001b[0m   | Flow run\u001b[35m 'hungry-copperhead'\u001b[0m - Finished in state \u001b[38;5;160mFailed\u001b[0m('Flow run encountered an exception. ValueError: too many values to unpack (expected 2)')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m08142024\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom-forest-regressor\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/flows.py:1237\u001b[0m, in \u001b[0;36mFlow.__call__\u001b[0;34m(self, return_state, wait_for, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m run_flow_sync(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrun_kwargs)\n\u001b[0;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menter_flow_run_engine_from_flow_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/engine.py:293\u001b[0m, in \u001b[0;36menter_flow_run_engine_from_flow_call\u001b[0;34m(flow, parameters, wait_for, return_type)\u001b[0m\n\u001b[1;32m    286\u001b[0m     retval \u001b[38;5;241m=\u001b[39m from_async\u001b[38;5;241m.\u001b[39mwait_for_call_in_loop_thread(\n\u001b[1;32m    287\u001b[0m         begin_run,\n\u001b[1;32m    288\u001b[0m         done_callbacks\u001b[38;5;241m=\u001b[39mdone_callbacks,\n\u001b[1;32m    289\u001b[0m         contexts\u001b[38;5;241m=\u001b[39mcontexts,\n\u001b[1;32m    290\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 293\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_sync\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_call_in_loop_thread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbegin_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdone_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdone_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/api.py:218\u001b[0m, in \u001b[0;36mfrom_sync.wait_for_call_in_loop_thread\u001b[0;34m(_from_sync__call, timeout, done_callbacks, contexts)\u001b[0m\n\u001b[1;32m    216\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(context)\n\u001b[1;32m    217\u001b[0m waiter\u001b[38;5;241m.\u001b[39mwait()\n\u001b[0;32m--> 218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:318\u001b[0m, in \u001b[0;36mCall.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    313\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    Wait for the result of the call.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    Not safe for use from asynchronous contexts.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:179\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Raise Prefect cancelled error instead of\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# `concurrent.futures._base.CancelledError`\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:389\u001b[0m, in \u001b[0;36mCall._run_async\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39menforce_async_deadline() \u001b[38;5;28;01mas\u001b[39;00m cancel_scope:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Forget this call's arguments in order to free up any memory\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# that may be referenced by them; after a call has happened,\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# there's no need to keep a reference to them\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/client/utilities.py:100\u001b[0m, in \u001b[0;36minject_client.<locals>.with_injected_client\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m new_client:\n\u001b[1;32m     99\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_client \u001b[38;5;129;01mor\u001b[39;00m client)\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/engine.py:396\u001b[0m, in \u001b[0;36mcreate_then_begin_flow_run\u001b[0;34m(flow, parameters, wait_for, return_type, client, user_thread)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m state\u001b[38;5;241m.\u001b[39mresult(fetch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid return type for flow engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_type\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/states.py:91\u001b[0m, in \u001b[0;36m_get_state_result\u001b[0;34m(state, raise_on_failure)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnfinishedRun(\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun is in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m state, its result is not available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_on_failure \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m     89\u001b[0m     state\u001b[38;5;241m.\u001b[39mis_crashed() \u001b[38;5;129;01mor\u001b[39;00m state\u001b[38;5;241m.\u001b[39mis_failed() \u001b[38;5;129;01mor\u001b[39;00m state\u001b[38;5;241m.\u001b[39mis_cancelled()\n\u001b[1;32m     90\u001b[0m ):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m get_state_exception(state)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state\u001b[38;5;241m.\u001b[39mdata, DataDocument):\n\u001b[1;32m     94\u001b[0m     result \u001b[38;5;241m=\u001b[39m result_from_state_with_data_document(\n\u001b[1;32m     95\u001b[0m         state, raise_on_failure\u001b[38;5;241m=\u001b[39mraise_on_failure\n\u001b[1;32m     96\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/engine.py:877\u001b[0m, in \u001b[0;36morchestrate_flow_run\u001b[0;34m(flow, flow_run, parameters, wait_for, interruptible, client, partial_flow_run_context, user_thread)\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m             from_async\u001b[38;5;241m.\u001b[39mcall_soon_in_new_thread(\n\u001b[1;32m    874\u001b[0m                 flow_call, timeout\u001b[38;5;241m=\u001b[39mflow\u001b[38;5;241m.\u001b[39mtimeout_seconds\n\u001b[1;32m    875\u001b[0m             )\n\u001b[0;32m--> 877\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m flow_call\u001b[38;5;241m.\u001b[39maresult()\n\u001b[1;32m    879\u001b[0m         waited_for_task_runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m wait_for_task_runs_and_report_crashes(\n\u001b[1;32m    880\u001b[0m             flow_run_context\u001b[38;5;241m.\u001b[39mtask_run_futures, client\u001b[38;5;241m=\u001b[39mclient\n\u001b[1;32m    881\u001b[0m         )\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PausedRun \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# could get raised either via utility or by returning Paused from a task run\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# if a task run pauses, we set its state as the flow's state\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m# to preserve reschedule and timeout behavior\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:327\u001b[0m, in \u001b[0;36mCall.aresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03mWait for the result of the call.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03mFor use from asynchronous contexts.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwrap_future(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture)\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError() \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py11/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:352\u001b[0m, in \u001b[0;36mCall._run_sync\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39menforce_sync_deadline() \u001b[38;5;28;01mas\u001b[39;00m cancel_scope:\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;66;03m# Forget this call's arguments in order to free up any memory\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;66;03m# that may be referenced by them; after a call has happened,\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;66;03m# there's no need to keep a reference to them\u001b[39;00m\n\u001b[1;32m    357\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(experiment_name, model_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m result \u001b[38;5;241m=\u001b[39m download_file(year, month)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m---> 11\u001b[0m usage_df_final, filename_output \u001b[38;5;241m=\u001b[39m prepare_dataset(year, month)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset usage to train is ready!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#preprocess_data load the usage dataset\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#testing flow from raw data\n",
    "experiment_name = '08142024'\n",
    "model_name = 'random-forest-regressor'\n",
    "main(experiment_name, model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow starting from prepared dataset - working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@flow\n",
    "def main(experiment_name, model_name):\n",
    "    experiment_id = mlflow_environment(experiment_name)\n",
    "    with mlflow.start_run(nested=True):\n",
    "        data_file = \"../data/processed/202304-usage.parquet\" \n",
    "        df = load_prepared_data(data_file)\n",
    "        mlflow.log_param(\"data_file\", data_file)\n",
    "        \n",
    "        # categorical encode\n",
    "        ohe, encoded_df = encode_categorical(df)\n",
    "        with open(f\"models/encoder-{experiment_name}-{experiment_id}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(ohe, f)\n",
    "        mlflow.log_artifact(f\"models/encoder-{experiment_name}-{experiment_id}.pkl\")\n",
    "\n",
    "        #split sets\n",
    "        split_params = {\"test_size\": 0.2, \"random_state\": 42}\n",
    "        X_train, X_test, y_train, y_test = split_data(encoded_df, split_params)\n",
    "        mlflow.log_param(\"split_params\", split_params)\n",
    "\n",
    "        #numerical scale\n",
    "        scaler, transformed_X_train, transformed_X_test, y_train, y_test = scale_numerical(X_train, X_test, y_train, y_test)\n",
    "        with open(f\"./models/scaler-{experiment_name}-{experiment_id}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        mlflow.log_artifact(f\"./models/scaler-{experiment_name}-{experiment_id}.pkl\")\n",
    "\n",
    "        \n",
    "        #saving sets\n",
    "        with open(f'../data/test_data/202304-usage-{experiment_name}-{experiment_id}.pkl', 'wb') as f:\n",
    "            pickle.dump((transformed_X_train, y_train, transformed_X_test, y_test), f)\n",
    "        transformed_test = pd.concat([transformed_X_test, y_test], axis =1)\n",
    "        transformed_test.to_parquet(f\"../deployment/data/202304-transformed_X_test-{experiment_name}-{experiment_id}.parquet\")\n",
    "\n",
    "        #saving data to GCS\n",
    "        train_test_filename= f'202304-usage-{experiment_name}-{experiment_id}.pkl'\n",
    "        test_filename = f'202304-transformed_X_test-{experiment_name}-{experiment_id}.parquet'\n",
    "        save_dataframes_gcs(transformed_X_train, y_train, transformed_X_test, y_test, train_test_filename, test_filename)\n",
    "\n",
    "\n",
    "        best_result = train_hyperparameter_tuning(transformed_X_train,transformed_X_test, y_train, y_test, model_name)\n",
    "        \n",
    "        print(experiment_id)\n",
    "        \n",
    "        model_version, model_uri = get_best_model(experiment_id)\n",
    "\n",
    "        print(model_version)\n",
    "        print(model_uri)\n",
    "\n",
    "        #os.environ['model_uri'] = model_uri\n",
    "        \n",
    "        promote_best_model(model_version, model_name)\n",
    "\n",
    "        #docker_up(container_names)\n",
    "        #prep_db()\n",
    "        #prepare_reference_data(model_uri, transformed_X_train, transformed_X_test)\n",
    "        #serve_model(model_uri)\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name ='experiment-20240813'\n",
    "model_name = \"random-forest-regressor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:02.241 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'main'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:02.241 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'sepia-lemming'\u001b[0m for flow\u001b[1;35m 'main'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:02.252 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://app.prefect.cloud/account/9a75fb5e-0068-4107-b908-7b1971037227/workspace/28c4637d-cdf0-4ac8-9a7b-138a3a8e9a50/flow-runs/flow-run/6083ea94-84d8-4c7d-8fda-d4068165f48a</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:02.252 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - View at \u001b[94mhttps://app.prefect.cloud/account/9a75fb5e-0068-4107-b908-7b1971037227/workspace/28c4637d-cdf0-4ac8-9a7b-138a3a8e9a50/flow-runs/flow-run/6083ea94-84d8-4c7d-8fda-d4068165f48a\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:02.709 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'mlflow_environment-0' for task 'mlflow_environment'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:02.709 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'mlflow_environment-0' for task 'mlflow_environment'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:02.713 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'mlflow_environment-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:02.713 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'mlflow_environment-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://34.171.118.161:5000'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:03.437 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'mlflow_environment-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:03.437 | \u001b[36mINFO\u001b[0m    | Task run 'mlflow_environment-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:03.740 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'load_prepared_data-0' for task 'load_prepared_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:03.740 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'load_prepared_data-0' for task 'load_prepared_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:03.741 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'load_prepared_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:03.741 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'load_prepared_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:04.296 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_prepared_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:04.296 | \u001b[36mINFO\u001b[0m    | Task run 'load_prepared_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:16.181 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'save_dataframes_gcs-0' for task 'save_dataframes_gcs'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:16.181 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'save_dataframes_gcs-0' for task 'save_dataframes_gcs'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:16.187 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'save_dataframes_gcs-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:16.187 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'save_dataframes_gcs-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:06:59.327 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'save_dataframes_gcs-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:06:59.327 | \u001b[36mINFO\u001b[0m    | Task run 'save_dataframes_gcs-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:06:59.539 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'train_hyperparameter_tuning-0' for task 'train_hyperparameter_tuning'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:06:59.539 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'train_hyperparameter_tuning-0' for task 'train_hyperparameter_tuning'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:06:59.541 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'train_hyperparameter_tuning-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:06:59.541 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'train_hyperparameter_tuning-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 12:11:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|        | 1/5 [04:24<17:38, 264.62s/trial, best loss: -21.826912973684998]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'random-forest-regressor'.\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 12:26:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|      | 2/5 [19:53<32:45, 655.23s/trial, best loss: -21.922722686254843]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'random-forest-regressor'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:42:49.912 | <span style=\"color: #d7d700; text-decoration-color: #d7d700\">WARNING</span> | urllib3.connectionpool - Retrying (Retry(total=4, connect=4, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x1643d9850&gt;: <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span> to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:42:49.912 | \u001b[38;5;184mWARNING\u001b[0m | urllib3.connectionpool - Retrying (Retry(total=4, connect=4, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1643d9850>: \u001b[38;5;160mFailed\u001b[0m to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:42:54.118 | <span style=\"color: #d7d700; text-decoration-color: #d7d700\">WARNING</span> | urllib3.connectionpool - Retrying (Retry(total=3, connect=3, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x170098050&gt;: <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span> to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:42:54.118 | \u001b[38;5;184mWARNING\u001b[0m | urllib3.connectionpool - Retrying (Retry(total=3, connect=3, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x170098050>: \u001b[38;5;160mFailed\u001b[0m to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:43:02.273 | <span style=\"color: #d7d700; text-decoration-color: #d7d700\">WARNING</span> | urllib3.connectionpool - Retrying (Retry(total=2, connect=2, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x16fd4e850&gt;: <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span> to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:43:02.273 | \u001b[38;5;184mWARNING\u001b[0m | urllib3.connectionpool - Retrying (Retry(total=2, connect=2, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x16fd4e850>: \u001b[38;5;160mFailed\u001b[0m to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:02:53.902 | <span style=\"color: #d7d700; text-decoration-color: #d7d700\">WARNING</span> | urllib3.connectionpool - Retrying (Retry(total=1, connect=1, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x1701c7790&gt;: <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span> to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:02:53.902 | \u001b[38;5;184mWARNING\u001b[0m | urllib3.connectionpool - Retrying (Retry(total=1, connect=1, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1701c7790>: \u001b[38;5;160mFailed\u001b[0m to establish a new connection: [Errno 51] Network is unreachable')': /api/2.0/mlflow/runs/log-metric\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 14:03:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|    | 3/5 [1:56:25<1:40:02, 3001.04s/trial, best loss: -21.99691175885226]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '4' of model 'random-forest-regressor'.\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 14:24:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|  | 4/5 [2:17:30<38:35, 2315.34s/trial, best loss: -22.074096583710904] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '5' of model 'random-forest-regressor'.\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/isabellevea/anaconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "Registered model 'random-forest-regressor' already exists. Creating a new version of this model...\n",
      "2024/08/13 14:26:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-regressor, version 6\n",
      "\n",
      "Created version '6' of model 'random-forest-regressor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [2:19:54<00:00, 1678.82s/trial, best loss: -22.074096583710904]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:54.636 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_hyperparameter_tuning-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:54.636 | \u001b[36mINFO\u001b[0m    | Task run 'train_hyperparameter_tuning-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:54.817 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'get_best_model-0' for task 'get_best_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:54.817 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'get_best_model-0' for task 'get_best_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:54.825 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'get_best_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:54.825 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'get_best_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:55.626 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'get_best_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:55.626 | \u001b[36mINFO\u001b[0m    | Task run 'get_best_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "runs:/1290d94d659f4f6da4202bec8927c2be/mlruns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:55.811 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Created task run 'promote_best_model-0' for task 'promote_best_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:55.811 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Created task run 'promote_best_model-0' for task 'promote_best_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:55.814 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Executing 'promote_best_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:55.814 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Executing 'promote_best_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/nb8m5vwd1sz3_s49jh1plcfr0000gn/T/ipykernel_10805/1789494125.py:6: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:56.367 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'promote_best_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:56.367 | \u001b[36mINFO\u001b[0m    | Task run 'promote_best_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:26:56.720 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'sepia-lemming'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:26:56.720 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'sepia-lemming'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `str`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `DataFrame`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `dict`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `tuple`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`'))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(experiment_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
